{"cells":[{"cell_type":"markdown","metadata":{"id":"G4i4VktTTFrQ"},"source":["### CONSIGNA: Clasificadores de Texto - Attention\n","Generar un modelo que como mínimo consista en un mecanismo de attention con un contextualizador convolucional. Ajustar los hiperparámentros para mejorar el accuracy. Se pueden extraer ideas de otros modelos como el TextCNN. Cambiar el contextualizador a una Bidir LSTM y comparar tiempos de entrenamiento y performance.\n","\n","* No se encuentra una notebook subida con el codigo de la cátedra ya que lo que es interesante para este TP se encuentra en esta notebook, mientras que las complicaciones que traia aparejada la tarea de correr el repo se resolvio durante la clase.\n","Por otro lado, cabe destacar la diferencia entre correrlo en collab con el GPU a correrlo en vscode en mi compu. El tiempo fue abismal.\n","* No tenia gensim y el enlace a drive no andaba, se empleo entonces los embeddings preentrenados de glove. En clase se comento la posibilidad de emplear fasttext tambien pero se prefiere mantener glove para mantener una comparacion frente a otros compañeros.\n","* En cuanto al tp: la idea principal de usar attention es que si bien uno tiene acceso a todo, en vez de ponderarlos de la misma forma, aplicas un criterio. Este criterio es aplicado por una sub-red dentro de nuestro modelo (en el caso de la bidir empleamos LSTM). Esta sub-red se encarga de estimar parámetros en funcion de t-1 y los estados actuales.\n","* La performance de accuracy aumenta más rápido al emplear CNN con attention que en BIDIR, en BIDIR tiene un aumento mas proporcional al pasar los epochs. Sin embargo, pese a que puede ser una complicación de la resolución llevada a cabo por mi, CNN parece overfitear mucho mas rápido que BIDIR.\n","* A destacar, el BIDIR se estanca en 0.5 mientras que la misma red llega a 0.8 cambiando glove por fasttext. Supongo esto tiene que ver con la naturalidad del embedding descargado, el de glove proviene de wikipedia mientras que el de fasttext de Facebook.\n","* En cuanto a tiempos de entrenamiento, las capas convolucionales de CNN en la notebook hacian parecer a la compu como un auto de f1; mientras que en google collab no se aprecia una diferencia clara respecto al costo de tiempo de entrenamiento.\n","* Si bien se recomendaba usar TEXTCNN se opto por la red 5 del repositorio ya que englobaba muchas cosas.\n","* El tiempo de entrenamiento de la red es similar, pero la bidir necesita muchas más epochs para converger (pero sus epochs son mucho mas cortas que la red convolucional)\n","################# TO-DO Escribir bien las conclusiones aunque ya se hablo todo en clase\n","\n","\n"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":15447,"status":"ok","timestamp":1695611170789,"user":{"displayName":"SEBASTIAN NAHUEL HERRERA","userId":"02078417289372018354"},"user_tz":180},"id":"ehW5bKOlTFrV"},"outputs":[],"source":["from sklearn.datasets import fetch_20newsgroups\n","from matplotlib import pyplot as plt\n","from collections import Counter\n","newsgroups_train = fetch_20newsgroups(subset='train')\n","newsgroups_test = fetch_20newsgroups(subset='test')\n","from keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","import numpy as np\n","import gensim\n","import os, re, csv, math, codecs\n","import numpy as np\n","import tensorflow as tf\n","from sklearn.preprocessing import LabelEncoder\n","from tensorflow.keras.layers import Input, Embedding, Conv1D, GlobalMaxPooling1D, Bidirectional, LSTM, Attention, Dense\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.callbacks import EarlyStopping\n","from keras.layers import Embedding, Conv1D, MaxPooling1D, GlobalMaxPooling1D, Dropout, Dense, Lambda\n","from keras.models import Sequential,Model\n","from keras import optimizers\n","import keras.backend as K\n"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1695611170790,"user":{"displayName":"SEBASTIAN NAHUEL HERRERA","userId":"02078417289372018354"},"user_tz":180},"id":"IVmnko_jTFrX"},"outputs":[],"source":["token=Tokenizer(num_words=30000, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True, split=' ', char_level=False, oov_token=\"UNK\", document_count=0)"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":2569,"status":"ok","timestamp":1695611173356,"user":{"displayName":"SEBASTIAN NAHUEL HERRERA","userId":"02078417289372018354"},"user_tz":180},"id":"hUmxkolgTFrY"},"outputs":[],"source":["token.fit_on_texts(newsgroups_train.data)"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":3717,"status":"ok","timestamp":1695611177066,"user":{"displayName":"SEBASTIAN NAHUEL HERRERA","userId":"02078417289372018354"},"user_tz":180},"id":"d6ReVG1DTFrZ"},"outputs":[],"source":["train_sequences=token.texts_to_sequences(newsgroups_train.data)\n","test_sequences=token.texts_to_sequences(newsgroups_test.data)\n"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1695611177067,"user":{"displayName":"SEBASTIAN NAHUEL HERRERA","userId":"02078417289372018354"},"user_tz":180},"id":"HNkIF8S5TFra"},"outputs":[],"source":["max_len=500\n","train_sequences=pad_sequences(train_sequences,maxlen=max_len)\n","test_sequences=pad_sequences(test_sequences,maxlen=max_len)"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1695611177542,"user":{"displayName":"SEBASTIAN NAHUEL HERRERA","userId":"02078417289372018354"},"user_tz":180},"id":"PrY2MATmTFra"},"outputs":[],"source":["reverse_dictionary = token.index_word\n","dictionary = dict([(value, key) for (key, value) in reverse_dictionary.items()])"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":305,"status":"ok","timestamp":1695611181842,"user":{"displayName":"SEBASTIAN NAHUEL HERRERA","userId":"02078417289372018354"},"user_tz":180},"id":"06WtmKrFTFrc"},"outputs":[],"source":["glove_path = 'glove.6B.300d.txt'\n","\n","\n","embeddings_index = {}\n","with open(glove_path, 'r', encoding='utf-8') as f:\n","    for line in f:\n","        values = line.split()\n","        word = values[0]\n","        coefs = np.asarray(values[1:], dtype='float32')\n","        embeddings_index[word] = coefs\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":382,"status":"ok","timestamp":1695611184094,"user":{"displayName":"SEBASTIAN NAHUEL HERRERA","userId":"02078417289372018354"},"user_tz":180},"id":"noBzuawzTFrd"},"outputs":[],"source":["# Define the dimensions\n","num_words = len(dictionary) + 1  # Add 1 for the padding token (if used)\n","embed_dim = 300  # Change this to match the dimension of your GloVe embeddings\n","\n","# Create an embedding matrix for your vocabulary\n","embedding_matrix = np.zeros((num_words, embed_dim))\n","\n","# Fill the embedding matrix with GloVe embeddings\n","for word, idx in dictionary.items():\n","    if idx < num_words and word in embeddings_index:\n","        embedding_vector = embeddings_index[word]\n","        embedding_matrix[idx] = embedding_vector\n","    else:\n","        # Handle out-of-vocabulary words here (e.g., use random initialization or zeros)\n","        pass"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":284,"status":"ok","timestamp":1695611188088,"user":{"displayName":"SEBASTIAN NAHUEL HERRERA","userId":"02078417289372018354"},"user_tz":180},"id":"z-SUCrVkTFre"},"outputs":[],"source":["import tensorflow as tf\n","K.clear_session()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GuR17pBXTFrf","outputId":"ce2f02df-0c3e-4422-e7b0-a5fc7545bf66"},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Python311\\Lib\\site-packages\\keras\\optimizers\\legacy\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super().__init__(name, **kwargs)\n"]}],"source":["from keras.layers import Embedding, Conv1D, Dense, Input, Concatenate,Dot,RepeatVector,TimeDistributed,Multiply,Lambda,Flatten, BatchNormalization\n","from tensorflow.keras.layers import Activation, MaxPooling1D, GlobalMaxPooling1D, Dropout, Reshape\n","import keras.backend as K\n","from keras.activations import softmax\n","from keras.models import Model\n","from keras import optimizers\n","value_dim=100\n","def softMaxOverTime(x):\n","    return softmax(x,axis=1)\n","\n","nb_words=num_words\n","num_filters=64\n","input_layer = Input(shape=(max_len,))\n","embedding_layer=Embedding(nb_words, embed_dim, weights=[embedding_matrix], input_length=max_len, trainable=False)(input_layer)\n","conv_out=Conv1D(value_dim,8,padding=\"same\")(embedding_layer)\n","conv_out=Activation(\"relu\")(conv_out)\n","conv_out=Conv1D(value_dim,8,activation=\"elu\",padding=\"same\")(conv_out)\n","ulog_attention=Dense(1,activation=\"linear\")(conv_out)\n","attention=Activation(softMaxOverTime)(ulog_attention)\n","repeated_attention=TimeDistributed(RepeatVector(value_dim))(attention)\n","repeated_attention=Reshape([max_len,value_dim])(repeated_attention)\n","weighted_embeddings=Multiply()([repeated_attention,conv_out])\n","embedding_sum = Lambda(lambda x: K.sum(x, axis=1))(weighted_embeddings)\n","dense1=Dense(1000, activation='relu')(embedding_sum)\n","dense1_2=Dense(100, activation='relu')(dense1)\n","dense2=Dense(20, activation='softmax')(dense1_2)\n","model=Model(input_layer , dense2)\n","adam = optimizers.Adam(lr=0.001, beta_1=0.999, beta_2=0.999, epsilon=1e-09, decay=0.0)\n","model.compile(loss='sparse_categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W0LW63XUTFrg","outputId":"265feaab-e4c0-42b6-ab44-3b0de66f4bd0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_1 (InputLayer)           [(None, 500)]        0           []                               \n","                                                                                                  \n"," embedding (Embedding)          (None, 500, 300)     40243200    ['input_1[0][0]']                \n","                                                                                                  \n"," conv1d (Conv1D)                (None, 500, 100)     240100      ['embedding[0][0]']              \n","                                                                                                  \n"," activation (Activation)        (None, 500, 100)     0           ['conv1d[0][0]']                 \n","                                                                                                  \n"," conv1d_1 (Conv1D)              (None, 500, 100)     80100       ['activation[0][0]']             \n","                                                                                                  \n"," dense (Dense)                  (None, 500, 1)       101         ['conv1d_1[0][0]']               \n","                                                                                                  \n"," activation_1 (Activation)      (None, 500, 1)       0           ['dense[0][0]']                  \n","                                                                                                  \n"," time_distributed (TimeDistribu  (None, 500, 100, 1)  0          ['activation_1[0][0]']           \n"," ted)                                                                                             \n","                                                                                                  \n"," reshape (Reshape)              (None, 500, 100)     0           ['time_distributed[0][0]']       \n","                                                                                                  \n"," multiply (Multiply)            (None, 500, 100)     0           ['reshape[0][0]',                \n","                                                                  'conv1d_1[0][0]']               \n","                                                                                                  \n"," lambda (Lambda)                (None, 100)          0           ['multiply[0][0]']               \n","                                                                                                  \n"," dense_1 (Dense)                (None, 1000)         101000      ['lambda[0][0]']                 \n","                                                                                                  \n"," dense_2 (Dense)                (None, 100)          100100      ['dense_1[0][0]']                \n","                                                                                                  \n"," dense_3 (Dense)                (None, 20)           2020        ['dense_2[0][0]']                \n","                                                                                                  \n","==================================================================================================\n","Total params: 40,766,621\n","Trainable params: 523,421\n","Non-trainable params: 40,243,200\n","__________________________________________________________________________________________________\n"]}],"source":["model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yNEGBFcRTFrg","outputId":"84ee3505-a736-429b-e2af-6953a26d63cf"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","37/37 [==============================] - 120s 3s/step - loss: 2.7110 - accuracy: 0.1429 - val_loss: 2.1725 - val_accuracy: 0.2545\n","Epoch 2/20\n","37/37 [==============================] - 108s 3s/step - loss: 1.9132 - accuracy: 0.3518 - val_loss: 1.6932 - val_accuracy: 0.4238\n","Epoch 3/20\n","37/37 [==============================] - 116s 3s/step - loss: 1.5229 - accuracy: 0.4671 - val_loss: 1.3856 - val_accuracy: 0.5214\n","Epoch 4/20\n","37/37 [==============================] - 105s 3s/step - loss: 1.2392 - accuracy: 0.5607 - val_loss: 1.1926 - val_accuracy: 0.5802\n","Epoch 5/20\n","37/37 [==============================] - 98s 3s/step - loss: 1.0701 - accuracy: 0.6197 - val_loss: 1.1095 - val_accuracy: 0.6151\n","Epoch 6/20\n","37/37 [==============================] - 100s 3s/step - loss: 0.9475 - accuracy: 0.6593 - val_loss: 1.0564 - val_accuracy: 0.6403\n","Epoch 7/20\n","37/37 [==============================] - 98s 3s/step - loss: 0.8642 - accuracy: 0.6898 - val_loss: 0.9577 - val_accuracy: 0.6792\n","Epoch 8/20\n","37/37 [==============================] - 98s 3s/step - loss: 0.7807 - accuracy: 0.7184 - val_loss: 0.9211 - val_accuracy: 0.6876\n","Epoch 9/20\n","37/37 [==============================] - 98s 3s/step - loss: 0.7136 - accuracy: 0.7499 - val_loss: 0.9167 - val_accuracy: 0.6986\n","Epoch 10/20\n","37/37 [==============================] - 104s 3s/step - loss: 0.6294 - accuracy: 0.7774 - val_loss: 0.9306 - val_accuracy: 0.7159\n","Epoch 11/20\n","37/37 [==============================] - 98s 3s/step - loss: 0.5730 - accuracy: 0.7986 - val_loss: 0.9072 - val_accuracy: 0.7344\n","Epoch 12/20\n","37/37 [==============================] - 100s 3s/step - loss: 0.5041 - accuracy: 0.8207 - val_loss: 0.9078 - val_accuracy: 0.7357\n","Epoch 13/20\n","37/37 [==============================] - 100s 3s/step - loss: 0.4517 - accuracy: 0.8448 - val_loss: 0.9097 - val_accuracy: 0.7605\n","Epoch 14/20\n","37/37 [==============================] - 99s 3s/step - loss: 0.3944 - accuracy: 0.8641 - val_loss: 0.8745 - val_accuracy: 0.7618\n","Epoch 15/20\n","37/37 [==============================] - 100s 3s/step - loss: 0.3587 - accuracy: 0.8782 - val_loss: 0.8670 - val_accuracy: 0.7746\n","Epoch 16/20\n","37/37 [==============================] - 100s 3s/step - loss: 0.3086 - accuracy: 0.8943 - val_loss: 0.9091 - val_accuracy: 0.7861\n","Epoch 17/20\n","37/37 [==============================] - 99s 3s/step - loss: 0.2751 - accuracy: 0.9045 - val_loss: 0.9721 - val_accuracy: 0.7888\n","Epoch 18/20\n","37/37 [==============================] - 99s 3s/step - loss: 0.2275 - accuracy: 0.9220 - val_loss: 1.0322 - val_accuracy: 0.7848\n","Epoch 19/20\n","37/37 [==============================] - 100s 3s/step - loss: 0.2036 - accuracy: 0.9291 - val_loss: 1.0361 - val_accuracy: 0.7870\n","Epoch 20/20\n","37/37 [==============================] - 100s 3s/step - loss: 0.1769 - accuracy: 0.9360 - val_loss: 1.1375 - val_accuracy: 0.7905\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x18b17066b10>"]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["model.fit(train_sequences, newsgroups_train.target,batch_size=250,epochs=20,validation_split=0.2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GtmYHPABTFrh"},"outputs":[],"source":["model.save(\"CNN+ATTENTION.h5\")\n"]},{"cell_type":"code","execution_count":106,"metadata":{"executionInfo":{"elapsed":420,"status":"ok","timestamp":1695619044131,"user":{"displayName":"SEBASTIAN NAHUEL HERRERA","userId":"02078417289372018354"},"user_tz":180},"id":"5_HfZQubTFrh"},"outputs":[],"source":["K.clear_session()"]},{"cell_type":"code","execution_count":107,"metadata":{"executionInfo":{"elapsed":1193,"status":"ok","timestamp":1695619060995,"user":{"displayName":"SEBASTIAN NAHUEL HERRERA","userId":"02078417289372018354"},"user_tz":180},"id":"HCAk7RoLTFrh"},"outputs":[],"source":["from keras.layers import Embedding, Concatenate,Dot,RepeatVector,TimeDistributed,Multiply,Lambda,Bidirectional, LSTM\n","from keras.layers import Conv1D, MaxPooling1D, GlobalMaxPooling1D, Dropout, Dense, Input\n","from keras.layers import Embedding, Conv1D, Dense, Input, Concatenate,Dot,RepeatVector,TimeDistributed,Multiply,Lambda,Flatten, BatchNormalization\n","from tensorflow.keras.layers import Activation, MaxPooling1D, GlobalMaxPooling1D, Dropout, Reshape\n","import keras.backend as K\n","from keras.activations import softmax\n","from keras.models import Model\n","from keras import optimizers\n","value_dim=100\n","\n","def softMaxOverTime(x):\n","    return softmax(x,axis=1)\n","\n","nb_words=num_words\n","num_filters=64\n","input_layer = Input(shape=(max_len,))\n","embedding_layer=Embedding(nb_words, embed_dim, weights=[embedding_matrix], input_length=max_len, trainable=False)(input_layer)\n","lstm_out=Bidirectional(LSTM(value_dim, return_sequences=True,activation=\"tanh\"),merge_mode=\"sum\")(embedding_layer)\n","conv_out=Conv1D(value_dim,64,padding=\"same\")(lstm_out)\n","conv_out=Activation(\"linear\")(conv_out)\n","conv_out=Conv1D(value_dim,64,activation=\"linear\",padding=\"same\")(conv_out)\n","ulog_attention=Dense(1,activation=\"linear\")(conv_out)\n","attention=Activation(softMaxOverTime)(ulog_attention)\n","repeated_attention=TimeDistributed(RepeatVector(value_dim))(attention)\n","repeated_attention=Reshape([max_len,value_dim])(repeated_attention)\n","weighted_embeddings=Multiply()([repeated_attention,lstm_out])\n","embedding_sum = Lambda(lambda x: K.sum(x, axis=1))(weighted_embeddings)\n","dense1=Dense(2000, activation='relu')(embedding_sum)\n","dense2=Dense(200, activation='softmax')(dense1)\n","model=Model(input_layer , dense2)\n","model.compile(loss='sparse_categorical_crossentropy', optimizer=\"rmsprop\", metrics=['accuracy'])"]},{"cell_type":"code","execution_count":108,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":309,"status":"ok","timestamp":1695619063480,"user":{"displayName":"SEBASTIAN NAHUEL HERRERA","userId":"02078417289372018354"},"user_tz":180},"id":"2a3iBKYhTFri","outputId":"012ed250-6fdd-490f-89b8-9f1dbf0c9714"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                Output Shape                 Param #   Connected to                  \n","==================================================================================================\n"," input_1 (InputLayer)        [(None, 500)]                0         []                            \n","                                                                                                  \n"," embedding (Embedding)       (None, 500, 300)             4024320   ['input_1[0][0]']             \n","                                                          0                                       \n","                                                                                                  \n"," bidirectional (Bidirection  (None, 500, 100)             320800    ['embedding[0][0]']           \n"," al)                                                                                              \n","                                                                                                  \n"," conv1d (Conv1D)             (None, 500, 100)             640100    ['bidirectional[0][0]']       \n","                                                                                                  \n"," activation (Activation)     (None, 500, 100)             0         ['conv1d[0][0]']              \n","                                                                                                  \n"," conv1d_1 (Conv1D)           (None, 500, 100)             640100    ['activation[0][0]']          \n","                                                                                                  \n"," dense (Dense)               (None, 500, 1)               101       ['conv1d_1[0][0]']            \n","                                                                                                  \n"," activation_1 (Activation)   (None, 500, 1)               0         ['dense[0][0]']               \n","                                                                                                  \n"," time_distributed (TimeDist  (None, 500, 100, 1)          0         ['activation_1[0][0]']        \n"," ributed)                                                                                         \n","                                                                                                  \n"," reshape (Reshape)           (None, 500, 100)             0         ['time_distributed[0][0]']    \n","                                                                                                  \n"," multiply (Multiply)         (None, 500, 100)             0         ['reshape[0][0]',             \n","                                                                     'bidirectional[0][0]']       \n","                                                                                                  \n"," lambda (Lambda)             (None, 100)                  0         ['multiply[0][0]']            \n","                                                                                                  \n"," dense_1 (Dense)             (None, 2000)                 202000    ['lambda[0][0]']              \n","                                                                                                  \n"," dense_2 (Dense)             (None, 200)                  400200    ['dense_1[0][0]']             \n","                                                                                                  \n","==================================================================================================\n","Total params: 42446501 (161.92 MB)\n","Trainable params: 2203301 (8.40 MB)\n","Non-trainable params: 40243200 (153.52 MB)\n","__________________________________________________________________________________________________\n"]}],"source":["model.summary()"]},{"cell_type":"code","execution_count":109,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":1121568,"status":"error","timestamp":1695620188644,"user":{"displayName":"SEBASTIAN NAHUEL HERRERA","userId":"02078417289372018354"},"user_tz":180},"id":"XzgW94lATFri","outputId":"23810580-b463-44fb-ad1e-ecef4a00835c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/50\n"]},{"name":"stderr","output_type":"stream","text":["Exception ignored in: <function _xla_gc_callback at 0x7877342cb490>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/jax/_src/lib/__init__.py\", line 98, in _xla_gc_callback\n","    def _xla_gc_callback(*args):\n","KeyboardInterrupt: \n"]},{"name":"stdout","output_type":"stream","text":["283/283 [==============================] - 161s 69ms/step - loss: 2.9856 - accuracy: 0.0872 - val_loss: 2.8068 - val_accuracy: 0.0897\n","Epoch 2/50\n","283/283 [==============================] - 20s 70ms/step - loss: 2.7039 - accuracy: 0.1435 - val_loss: 2.5413 - val_accuracy: 0.1617\n","Epoch 3/50\n","283/283 [==============================] - 19s 66ms/step - loss: 2.5297 - accuracy: 0.1775 - val_loss: 2.4502 - val_accuracy: 0.2028\n","Epoch 4/50\n","283/283 [==============================] - 19s 66ms/step - loss: 2.4699 - accuracy: 0.2052 - val_loss: 2.3710 - val_accuracy: 0.2360\n","Epoch 5/50\n","283/283 [==============================] - 19s 66ms/step - loss: 2.3680 - accuracy: 0.2318 - val_loss: 2.2464 - val_accuracy: 0.2391\n","Epoch 6/50\n","283/283 [==============================] - 19s 66ms/step - loss: 2.2097 - accuracy: 0.2685 - val_loss: 2.1273 - val_accuracy: 0.2863\n","Epoch 7/50\n","283/283 [==============================] - 19s 68ms/step - loss: 2.1145 - accuracy: 0.2981 - val_loss: 2.1473 - val_accuracy: 0.3014\n","Epoch 8/50\n","283/283 [==============================] - 19s 66ms/step - loss: 1.9886 - accuracy: 0.3370 - val_loss: 2.0212 - val_accuracy: 0.3363\n","Epoch 9/50\n","283/283 [==============================] - 19s 66ms/step - loss: 2.0056 - accuracy: 0.3460 - val_loss: 2.0020 - val_accuracy: 0.3411\n","Epoch 10/50\n","283/283 [==============================] - 19s 66ms/step - loss: 1.9064 - accuracy: 0.3777 - val_loss: 2.0506 - val_accuracy: 0.3177\n","Epoch 11/50\n","283/283 [==============================] - 19s 66ms/step - loss: 1.7591 - accuracy: 0.4233 - val_loss: 1.9038 - val_accuracy: 0.3716\n","Epoch 12/50\n","283/283 [==============================] - 19s 66ms/step - loss: 1.6473 - accuracy: 0.4539 - val_loss: 1.9399 - val_accuracy: 0.3743\n","Epoch 13/50\n","283/283 [==============================] - 19s 66ms/step - loss: 1.5459 - accuracy: 0.4826 - val_loss: 1.8756 - val_accuracy: 0.4114\n","Epoch 14/50\n","283/283 [==============================] - 20s 72ms/step - loss: 1.4546 - accuracy: 0.5234 - val_loss: 1.7969 - val_accuracy: 0.4317\n","Epoch 15/50\n","283/283 [==============================] - 19s 67ms/step - loss: 1.3562 - accuracy: 0.5504 - val_loss: 1.7920 - val_accuracy: 0.4339\n","Epoch 16/50\n","283/283 [==============================] - 19s 66ms/step - loss: 1.2669 - accuracy: 0.5813 - val_loss: 1.8294 - val_accuracy: 0.4551\n","Epoch 17/50\n","283/283 [==============================] - 19s 66ms/step - loss: 1.1724 - accuracy: 0.6111 - val_loss: 1.8365 - val_accuracy: 0.4702\n","Epoch 18/50\n","283/283 [==============================] - 19s 66ms/step - loss: 1.0861 - accuracy: 0.6436 - val_loss: 1.8672 - val_accuracy: 0.4706\n","Epoch 19/50\n","283/283 [==============================] - 20s 70ms/step - loss: 0.9906 - accuracy: 0.6786 - val_loss: 2.0954 - val_accuracy: 0.4410\n","Epoch 20/50\n","283/283 [==============================] - 19s 65ms/step - loss: 0.9052 - accuracy: 0.7025 - val_loss: 1.9276 - val_accuracy: 0.4856\n","Epoch 21/50\n","283/283 [==============================] - 19s 66ms/step - loss: 0.8204 - accuracy: 0.7346 - val_loss: 2.0644 - val_accuracy: 0.4715\n","Epoch 22/50\n","283/283 [==============================] - 19s 68ms/step - loss: 0.7340 - accuracy: 0.7591 - val_loss: 2.2311 - val_accuracy: 0.4790\n","Epoch 23/50\n","283/283 [==============================] - 19s 66ms/step - loss: 0.6609 - accuracy: 0.7869 - val_loss: 2.3078 - val_accuracy: 0.4874\n","Epoch 24/50\n","283/283 [==============================] - 19s 66ms/step - loss: 0.5856 - accuracy: 0.8160 - val_loss: 2.4766 - val_accuracy: 0.4781\n","Epoch 25/50\n","283/283 [==============================] - 20s 70ms/step - loss: 0.5172 - accuracy: 0.8364 - val_loss: 2.3564 - val_accuracy: 0.4856\n","Epoch 26/50\n","283/283 [==============================] - 19s 66ms/step - loss: 0.4815 - accuracy: 0.8550 - val_loss: 2.5746 - val_accuracy: 0.4892\n","Epoch 27/50\n","283/283 [==============================] - 19s 66ms/step - loss: 0.4165 - accuracy: 0.8713 - val_loss: 2.6012 - val_accuracy: 0.4954\n","Epoch 28/50\n","283/283 [==============================] - 19s 66ms/step - loss: 0.3771 - accuracy: 0.8839 - val_loss: 2.8758 - val_accuracy: 0.4839\n","Epoch 29/50\n","283/283 [==============================] - 19s 66ms/step - loss: 0.3515 - accuracy: 0.8967 - val_loss: 2.8565 - val_accuracy: 0.4958\n","Epoch 30/50\n","283/283 [==============================] - 19s 68ms/step - loss: 0.3112 - accuracy: 0.9066 - val_loss: 3.0801 - val_accuracy: 0.4967\n","Epoch 31/50\n","283/283 [==============================] - 19s 66ms/step - loss: 0.2986 - accuracy: 0.9158 - val_loss: 2.9114 - val_accuracy: 0.4954\n","Epoch 32/50\n","283/283 [==============================] - 19s 66ms/step - loss: 0.2828 - accuracy: 0.9205 - val_loss: 3.0162 - val_accuracy: 0.4905\n","Epoch 33/50\n","283/283 [==============================] - 19s 66ms/step - loss: 0.2604 - accuracy: 0.9263 - val_loss: 3.1532 - val_accuracy: 0.4918\n","Epoch 34/50\n","283/283 [==============================] - 19s 66ms/step - loss: 0.2353 - accuracy: 0.9345 - val_loss: 3.1045 - val_accuracy: 0.4936\n","Epoch 35/50\n","283/283 [==============================] - 19s 66ms/step - loss: 0.2400 - accuracy: 0.9319 - val_loss: 3.3963 - val_accuracy: 0.4843\n","Epoch 36/50\n","283/283 [==============================] - 19s 66ms/step - loss: 0.2085 - accuracy: 0.9442 - val_loss: 3.2928 - val_accuracy: 0.4821\n","Epoch 37/50\n","283/283 [==============================] - 20s 71ms/step - loss: 0.1941 - accuracy: 0.9453 - val_loss: 3.3578 - val_accuracy: 0.4967\n","Epoch 38/50\n","283/283 [==============================] - 19s 68ms/step - loss: 0.1772 - accuracy: 0.9493 - val_loss: 3.3698 - val_accuracy: 0.5051\n","Epoch 39/50\n","283/283 [==============================] - 19s 66ms/step - loss: 0.1878 - accuracy: 0.9461 - val_loss: 3.3549 - val_accuracy: 0.5046\n","Epoch 40/50\n","283/283 [==============================] - 19s 66ms/step - loss: 0.1513 - accuracy: 0.9571 - val_loss: 3.6873 - val_accuracy: 0.5007\n","Epoch 41/50\n","283/283 [==============================] - 19s 66ms/step - loss: 0.1784 - accuracy: 0.9519 - val_loss: 3.7994 - val_accuracy: 0.4896\n","Epoch 42/50\n","283/283 [==============================] - 19s 66ms/step - loss: 0.1474 - accuracy: 0.9579 - val_loss: 3.8583 - val_accuracy: 0.4923\n","Epoch 43/50\n","283/283 [==============================] - 19s 66ms/step - loss: 0.1751 - accuracy: 0.9548 - val_loss: 3.7106 - val_accuracy: 0.5095\n","Epoch 44/50\n","283/283 [==============================] - 19s 66ms/step - loss: 0.1970 - accuracy: 0.9476 - val_loss: 4.0019 - val_accuracy: 0.4932\n","Epoch 45/50\n","283/283 [==============================] - 20s 70ms/step - loss: 0.1623 - accuracy: 0.9551 - val_loss: 3.8478 - val_accuracy: 0.4989\n","Epoch 46/50\n","283/283 [==============================] - 20s 71ms/step - loss: 0.1750 - accuracy: 0.9568 - val_loss: 3.6783 - val_accuracy: 0.4852\n","Epoch 47/50\n","283/283 [==============================] - 19s 66ms/step - loss: 0.1501 - accuracy: 0.9607 - val_loss: 3.7955 - val_accuracy: 0.4958\n","Epoch 48/50\n","283/283 [==============================] - 20s 71ms/step - loss: 0.1776 - accuracy: 0.9546 - val_loss: 3.8168 - val_accuracy: 0.4980\n","Epoch 49/50\n","283/283 [==============================] - 19s 66ms/step - loss: 0.1628 - accuracy: 0.9609 - val_loss: 4.1664 - val_accuracy: 0.4949\n","Epoch 50/50\n","283/283 [==============================] - 19s 66ms/step - loss: 0.1624 - accuracy: 0.9593 - val_loss: 3.8844 - val_accuracy: 0.5086\n"]},{"ename":"KeyboardInterrupt","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-109-a6cfb30a9d3a>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_sequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewsgroups_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["model.fit(train_sequences, newsgroups_train.target,batch_size=32,epochs=50,validation_split=0.2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QmYrsg8STFri"},"outputs":[],"source":["model.save(\"BIDIR+ATTENTION.h5\")\n","K.clear_session()"]},{"cell_type":"markdown","metadata":{"id":"R_sRc31oTFrj"},"source":["Helpers producto de redes1 por si necesito usar en algun momento"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xWqWFZczTFrj"},"outputs":[],"source":["K.clear_session()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4MPrNsQCTFrk"},"outputs":[],"source":["model.save(\"modelo.h5\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-j47_uTJTFrk"},"outputs":[],"source":["early_stopping = EarlyStopping(patience=3, restore_best_weights=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H6ySzsArTFrk"},"outputs":[],"source":["model.fit(train_x, train_y,batch_size=28,epochs=30,validation_split=0.2,callbacks=[early_stopping])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NuItfccNTFrk"},"outputs":[],"source":["txt_path = 'path/to/x.txt'\n","word_to_vec = {}\n","with open(glove_path, 'r', encoding='utf-8') as f:\n","    for line in f:\n","        values = line.split()\n","        word = values[0]\n","        vector = np.array(values[1:], dtype='float32')\n","        word_to_vec[word] = vector"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.0"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}
